# SD-VLA：通过静态-动态解耦实现高效长时程 VLA 模型——原理详解

> 论文：*Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement*
> 机构：Yale University
> 发布时间：2026年2月
> 🔗 [arXiv](https://arxiv.org/abs/2602.03983) | [PDF](https://arxiv.org/pdf/2602.03983)

---

## 一、论文要解决什么问题？

### 1.1 VLA 模型面临的双重挑战

VLA（Vision-Language-Action）模型在通用机器人控制中表现出色，但面临两个相互关联的核心挑战：

**挑战一：有限的长时程上下文**
- 当前大多数 VLA 以**无记忆**方式运行（$T=0$，仅看当前帧），无法处理需要时序依赖的任务
- 例如，指令"按一下按钮"——VLA 必须记住按钮是否已被按下，否则会无限重复同一动作
- 简单拼接多帧？每帧产生数百个视觉 token，Transformer 的二次复杂度使得上下文长度爆炸

**挑战二：推理效率低下**
- VLA 模型参数量大（7B+），每步推理延迟高
- 真实场景要求快速响应（家务助手要高效、安全场景需要近实时反应）
- RL 后训练需要大量 rollout，推理速度成为关键瓶颈

### 1.2 现有方法的局限

**通用加速方法**（量化、token/层剪枝）：
- 直接迁移自通用 ML 模型的加速技术
- **忽略了 VLA 任务的固有特性**——连续帧之间存在大量时间冗余

**时间冗余利用方法**（[VLA-Cache](/papers/06-embodied-ai/vla/efficient/VLA_Cache_2025)、TTF-VLA 等）：
- 通过 KV 缓存复用或动作复用来利用帧间冗余
- 但依赖**启发式的、不可学习的标准**
- 关键问题：**假设像素空间的视觉相似性等同于隐空间表示的一致性——这在 Transformer 架构中并不成立**

> 如下图所示：即使两帧中某些 patch 在像素空间完全相同（如静态背景），经过 Transformer 的注意力机制后，它们的隐表示已经因为与其他动态 token 的交互而发生了改变。VLA-Cache 等方法忽略了这一点。

### 1.3 SD-VLA 的核心洞察

SD-VLA 的核心思路可以用一句话概括：**显式地将视觉 token 解耦为静态和动态两类，通过架构设计确保静态 token 在隐空间中也保持不变，从而安全地跨帧复用。**

具体来说：

1. **静态 token 放在所有动态 token 前面**：利用因果注意力的单向性，静态 token 不会被后面的动态 token 影响，因此其隐表示在 LLM 各层中始终保持一致
2. **多级静态层次**：不同信息有不同的时间持久性——背景可能持续数十步不变，而物体外观可能因遮挡频繁变化
3. **可学习的重缓存门**：自适应决定何时刷新缓存，而非靠固定规则

**最终效果**：
- **长时程**：LIBERO-Memory 基准上成功率提升 **39.8%**
- **加速**：SimplerEnv 上实现 **2.26×** 推理加速，同时成功率 **+4.9%**
- **兼得**：长时程建模能力和推理效率可以同时获得

---

## 二、预备知识

### 2.1 VLA 模型的标准推理流程

标准 VLA 模型在每个时间步 $t$ 接收环境观测 $X_t$，由视觉编码器将其编码为 $N$ 个视觉 token $Z_t = z_{t,1}, z_{t,2}, \cdots, z_{t,N}$，然后送入 LLM 骨架预测动作：

$$\pi: (X_{t-T}, X_{t-T+1}, \cdots, X_t, \mathcal{I}) \mapsto a_t, a_{t+1}, \cdots$$

当前绝大多数 VLA 因为上下文限制只能使用 $T=0$（仅当前帧）。

### 2.2 因果注意力与 KV 缓存

在自回归 Transformer 中，因果注意力确保每个 token 只能关注它之前的 token。这意味着：

- 如果静态 token 被放在动态 token **前面**，它们在 LLM 中的 KV 表示只取决于自身和更前面的静态 token，不受后面动态 token 的影响
- 这一性质使得静态 token 的 KV 缓存可以在语义上安全地跨帧复用

### 2.3 对比学习与 InfoNCE

SD-VLA 使用 InfoNCE 对比损失来训练静态 token 的时间持久性：

- **正样本对**：同一轨迹不同时间步的静态 token 表示（应该相似）
- **负样本对**：不同轨迹的静态 token 表示（应该不同）

这确保静态 token 在时间窗口内保持稳定，同时仍编码任务相关信息。

### 2.4 Gumbel-Softmax

SD-VLA 使用 Gumbel-Softmax 技巧训练重缓存门的离散决策（刷新/复用），实现端到端可微分的二值决策学习。

---

## 三、方法论详解

### 3.1 静态-动态解耦架构

#### 基本解耦

SD-VLA 将视觉 token 显式拆分为静态和动态两部分：

$$Z_t = Z_t^s, Z_t^d = \underbrace{z_{t,1}, \cdots, z_{t,N_s}}_{\text{static tokens}}, \underbrace{z_{t,1}, \cdots, z_{t,N_d}}_{\text{dynamic tokens}}$$

#### 多级静态层次

静态信息本身存在不同的时间尺度。例如，全局场景布局可能持续很长时间不变，而物体外观可能因交互而更频繁变化。SD-VLA 引入多级静态 token：

$$Z_t^{s_1}, Z_t^{s_2}, \cdots, Z_t^d = \underbrace{z_{t,1}, \cdots, z_{t,N_{s_1}}}_{\text{L1 static（最持久）}}, \underbrace{z_{t,1}, \cdots, z_{t,N_{s_2}}}_{\text{L2 static（中等持久）}}, \cdots, \underbrace{z_{t,1}, \cdots, z_{t,N_d}}_{\text{dynamic（每步更新）}}$$

**关键设计**：在输入 LLM 时，按 `L1 static → L2 static → ... → dynamic` 的顺序排列。由于因果注意力的单向性，静态 token 不会被后面的动态 token "污染"，确保其隐表示在 LLM 各层中始终不变。

> 这是 SD-VLA 与 VLA-Cache 等方法的**根本区别**：VLA-Cache 在原始 token 顺序中缓存 KV，但由于双向注意力交互，"静态"token 的隐表示实际上已被动态 token 影响。SD-VLA 通过架构设计从根本上消除了这一问题。

### 3.2 长时程时序建模

有了静态-动态解耦，多帧输入变得高效：

$$a_t, a_{t+1}, \cdots = \pi_{\text{LLM}}(Z^{s_1}, Z^{s_2}, \cdots, Z_{t-T}^d, \cdots, Z_t^d)$$

- **静态 token**：在整个时间窗口内只保留**一份**
- **动态 token**：每步各自独立拼接

上下文长度从原来的 $NT$ 减少为 $rN + (1-r)NT = NT - rN(T-1)$，其中 $r$ 是静态 token 的比例。

**实际配置**（记忆实验）：静态比例 90%，230 个静态 token + 26 个动态 token，20 帧历史，仅需 750 个上下文 token 即可覆盖 20 步时序信息。

### 3.3 可学习的重缓存门（Recache Gate）

单纯永远复用静态缓存是不安全的——场景终究会发生变化（如物体被搬到新位置）。SD-VLA 为每个静态层级引入可学习的重缓存门：

$$g_l(Z_{t-\Delta}, Z_t) \in [0, 1], \quad \Delta = 1, 2, \cdots, T$$

它根据当前帧和缓存参考帧的视觉 token，预测是否需要刷新静态缓存。

**训练时**：使用 Gumbel-Softmax 实现端到端可微分的二值决策。

**推理时**：当 $g_l > \delta_l$ 时刷新缓存，否则复用。

**层级联动**：如果高层缓存（L1）需要刷新，低层缓存（L2）也强制刷新。这确保了缓存一致性。

**重缓存门架构**：轻量级 MLP 设计——输入两帧的视觉 backbone 输出，经过 position-wise FFN → 转置 → channel-wise FFN → 展平 + 线性层 → 输出重缓存概率。不同静态层级共享所有参数，仅最终预测头不同。开销仅约 **1.27%**。

### 3.4 训练目标

总损失函数由三部分组成：

$$\mathcal{L} = \mathcal{L}_{\text{Task}} + \alpha_l \sum_l \mathcal{L}_{\text{InfoNCE}}^l + \beta \mathcal{L}_{\text{gate}}$$

#### （1）任务损失 $\mathcal{L}_{\text{Task}}$

标准 VLA 的动作预测损失，保证任务性能。

#### （2）对比正则化 $\mathcal{L}_{\text{InfoNCE}}^l$

确保每个层级的静态 token 具有时间持久性：

- **正样本**：同一轨迹中不同时间步的静态 token → 应该相似
- **负样本**：不同轨迹的静态 token → 应该不同

这促使模型学会将时间持久的视觉信息（如背景、静物）分配给静态 token。

#### （3）重缓存门正则化 $\mathcal{L}_{\text{gate}}$

如果仅用任务损失训练，门倾向于**每步都刷新**（平凡解，无加速收益）。为此引入先验正则：

$$\mathcal{L}_{\text{gate}} = -p_{\Delta} \log g - (1 - p_{\Delta}) \log(1 - g)$$

其中 $p_{\Delta_t} = 1 - e^{-\lambda \Delta_t}$ 是预定义先验——只有当时间间隔 $\Delta$ 足够大时才倾向于刷新。这平衡了效率和性能。

**超参设置**：$\alpha_1 = 0.2, \alpha_2 = 0.1, \beta = 0.1$。

### 3.5 计算复杂度分析

设 $N$ 为总 token 数，$r$ 为缓存比例，$N' = (1-r)N$ 为需重算的 token 数。

**标准 LLM 前向 FLOPs**：

$$F = 4Nd^2 + 2N^2d + 2Ndm$$

**SD-VLA 前向 FLOPs**（静态 token 已缓存）：

$$F' = 4N'd^2 + 2NN'd + 2N'dm$$

**理论加速比**：

$$\frac{F'}{F} = (1-r) \cdot \frac{4d^2 + 2Nd + 2dm}{4d^2 + 2Nd + 2dm} = 1 - r$$

即 LLM 骨架的 FLOPs 理论上可降至 $1-r$。实际加速会被视觉骨架、解码模块和缓存刷新步骤稀释，但这些组件的计算量远小于 LLM 骨架。

---

## 四、实验结果

### 4.1 LIBERO-Memory：时序依赖建模

SD-VLA 提出了全新的 **LIBERO-Memory** 基准，专门评估 VLA 的时序依赖建模能力。该基准受人类情景记忆（episodic memory）启发，要求机器人记住 what（哪个罐子被加热过）、where（原始位置在哪）、when（加热了多久）。

| 模型 | On Stove ↑ | Position Reset ↑ | Doneness ↓ |
| --- | --- | --- | --- |
| TTF-VLA | 7.8% | 1.5% | 1.51 |
| TraceVLA | 2.0% | 3.0% | 1.41 |
| MemoryVLA | 23.0% | 2.0% | 1.49 |
| ContextVLA | 50.8% | 22.3% | 0.37 |
| **SD-VLA** | **69.8%** | **83.0%** | **0.26** |

**关键发现**：

1. **SD-VLA 全面大幅领先**——On Stove 成功率 69.8%（次优方法仅 50.8%），Position Reset 83.0%（次优仅 22.3%）
2. **单帧方法几乎完全失败**——TraceVLA 仅 2.0%/3.0%，证明了此任务确实需要时序记忆
3. **ContextVLA 受限于不可学习的池化**——丢失了关键的时空细节
4. **MemoryVLA 受限于架构**——LLM 骨架每步只看单帧，多帧推理交给轻量解码器，能力不足

### 4.2 SimplerEnv：加速性能

| 方法 | VM-PickCan | VM-MoveNear | VM-Drawer | VA-PickCan | VA-MoveNear | VA-Drawer | FLOPs | 延迟(ms) | 加速比 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| CogACT（基线） | 91.3 | 85.0 | 71.8 | 89.6 | 80.8 | 28.3 | 100% | 1360 | 1.00× |
| + FlashVLA | 80.0 | 57.1 | 73.6 | 82.5 | 60.8 | 28.6 | 83.4% | 1024 | 1.33× |
| + TTF | 89.3 | 71.3 | 58.4 | 88.0 | 62.7 | 34.0 | 86.5% | 1051 | 1.29× |
| + VLA-Cache | 92.0 | 83.3 | 70.5 | 91.7 | 79.3 | 32.5 | 80.1% | 985 | 1.38× |
| **+ SD-VLA** | **92.7** | **88.8** | **75.0** | **92.4** | **81.0** | **38.9** | **43.4%** | **601** | **2.26×** |

**关键发现**：

1. **SD-VLA 是唯一同时大幅提速和提升性能的方法**——成功率 +4.9%，加速 2.26×
2. **FLOPs 降至 43.4%**——远超所有基线（VLA-Cache 为 80.1%），得益于高静态比例（约 94% 的 token 为静态）
3. **FlashVLA（动作复用）性能严重下降**——简单复用前一步动作丢失了太多信息
4. **TTF-VLA 在部分任务上表现不稳**——patch-wise 混合方式可能引入伪影

### 4.3 LIBERO：通用性验证

| 模型 | Spatial | Object | Goal | Long | 平均 | FLOPs | 延迟(ms) | 加速比 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| OpenVLA-OFT（基线） | 96.2 | 98.3 | 96.2 | 90.7 | 95.4 | 100.0% | 741 | 1.00× |
| + FlashVLA | 71.8 | 90.0 | 79.2 | 78.8 | 80.0 | 88.7% | 657 | 1.13× |
| + TTF | 95.8 | 94.2 | 93.6 | 86.0 | 92.4 | 75.0% | 575 | 1.29× |
| + VLA-Cache | 95.6 | 92.8 | 94.0 | 89.6 | 93.0 | 85.5% | 652 | 1.14× |
| **+ SD-VLA** | **97.8** | 97.6 | **96.2** | **92.4** | **96.0** | **63.4%** | **437** | **1.70×** |

在以 OpenVLA-OFT 为基座的 LIBERO 上，SD-VLA 同样以最快速度实现最高性能（+0.6pp，1.70× 加速）。

### 4.4 消融实验

| 配置 | VM-PickCan | VM-MoveNear | VA-PickCan | VA-MoveNear |
| --- | --- | --- | --- | --- |
| **SD-VLA（完整）** | **92.7** | **88.8** | **92.4** | **81.0** |
| w/o 对比学习 | 91.3 | 84.6 | 91.6 | 82.7 |
| w/o L2 cache | 92.0 | 85.0 | 91.5 | 81.5 |
| 固定步长刷新 | 87.7 | 81.7 | 85.3 | 74.8 |

- **对比学习**：移除后 MoveNear 下降 4.2pp，没有显式的时间一致性约束，静态 token 无法保证跨帧稳定
- **多级缓存**：移除 L2 后性能下降，不同粒度的时间持久性需要多级建模
- **可学习门 vs 固定间隔**：固定步长刷新性能骤降（MoveNear: 81.0→74.8），自适应刷新远优于人工规则

### 4.5 注意力可视化

SD-VLA 的注意力图清晰展示了三类 token 的分工：

- **Dynamic token**：持续关注**可移动物体**（机械夹爪、苹果），捕捉动作相关的时变元素
- **L1 Static token**：关注**背景和环境区域**，充当 sink token 捕捉全局场景上下文，注意力模式跨时间步高度一致
- **L2 Static token**：关注**半静态物体**（如抽屉），在物体状态变化后稳定下来。$t=0$ 时两个抽屉把手都被关注，开抽屉后（$t>100$）注意力稳定在抽屉结构上

---

## 五、用类比总结 SD-VLA 的核心原理

想象你在翻阅一本关于烹饪的漫画：

**传统 VLA**：每翻一页都从头仔细看整页——厨房的墙壁、窗户、灶台、食材、厨师的手。即使只有厨师的手在动，背景完全一样，也要全部重新"阅读"。而且一次只能看**一页**（无记忆），做多步任务时完全不记得前面发生了什么。

**VLA-Cache**：发现很多区域没变就跳过不看，但判断标准是"像素看起来一样"。问题是漫画的着色和阴影可能因为上下文而微妙变化，即使原始线稿一样，实际"理解"已经不同了。

**SD-VLA 的做法**：先把漫画的内容分成三层——

1. **L1 背景板**（厨房墙壁、窗外风景）：整个故事只画一张，后续每页直接垫在底下
2. **L2 道具层**（灶台、锅碗）：偶尔重画（比如锅被移走了才更新）
3. **动态层**（厨师的手、食材变化）：每页重新画

关键在于背景板**放在最底层**，上层的动态变化不会"渗透"回去影响背景。这样你既能高效翻阅（省去重复阅读背景的时间），又能回顾之前 20 页的关键动态信息（因为只需要记住每页的"动态层"小卡片），还有一个聪明的助手帮你判断"背景板是不是该换了"。

---

## 六、局限性与未来方向

### 6.1 基于预训练 VLA 的微调策略

SD-VLA 当前是在预训练好的 VLA 上进行微调。这种策略可能无法完全释放模型潜力。未来可以探索从头预训练带有静态-动态解耦架构的 VLA。

### 6.2 静态比例的先验假设

当前静态/动态 token 的数量比例是超参数（如 90% 静态），不同任务场景的最优比例可能不同。虽然多级缓存提供了一定灵活性，但一个完全自适应的动态分配机制可能更优。

### 6.3 未来方向

- **从头预训练**：直接在 VLA 预训练阶段引入静态-动态架构，而非作为后处理微调
- **动态 token 比例**：结合 [LAC](/papers/06-embodied-ai/vla/efficient/LAC_2026) 的可学习比例预测思路，让模型自适应决定每步的静态/动态比例
- **扩展到 Flow Matching VLA**：验证在 [π₀](/papers/06-embodied-ai/vla/foundation/pi0_2024) 等 Flow Matching 架构上的效果

---

## 七、个人思考

### 7.1 解决了 VLA-Cache 的根本缺陷

SD-VLA 论文中对 VLA-Cache 的批评非常精准：**像素空间的静态性不等于隐空间的静态性**。在标准 Transformer 中，即使一个 patch 在像素空间完全不变，由于注意力机制与其他动态 token 的交互，其隐表示会逐层改变。SD-VLA 通过将静态 token 放在前面、利用因果注意力的单向性，从架构层面**保证**了隐表示的跨帧一致性。这是一个优雅且有理论支撑的解决方案。

### 7.2 三篇高效推理论文的对比

| 维度 | VLA-Cache | LAC | SD-VLA |
| --- | --- | --- | --- |
| **核心思路** | 基于规则的 KV 缓存复用 | 可学习的缓存策略 | 静态-动态架构解耦 |
| **是否需要训练** | 否（即插即用） | 是（两阶段） | 是（LoRA 微调） |
| **静态性判断** | 像素余弦相似度 + 注意力分数 | 光流运动先验 + 端到端学习 | 对比学习 + 因果注意力保证 |
| **隐空间一致性** | 不保证 | 不保证（但通过学习缓解） | 架构保证 |
| **长时程建模** | 否 | 否 | 是（多帧紧凑上下文） |
| **最大加速** | 1.7× | 1.76× | 2.26× |
| **适用场景** | 快速部署、不改模型 | 中等部署成本、需训练 | 需要长时程记忆 + 高加速 |

三种方法体现了不同的设计哲学：VLA-Cache 追求零成本部署，LAC 追求可学习的最优策略，SD-VLA 追求从架构层面的根本解决。

### 7.3 "加速+长时程"的双赢设计

SD-VLA 最精妙的地方在于其静态-动态解耦**同时解决了两个看似矛盾的问题**：

- **加速**：静态 token 的 KV 缓存可以跨帧复用 → 减少计算量
- **长时程建模**：静态 token 只保留一份 + 动态 token 逐帧拼接 → 大幅压缩上下文长度，使得在有限窗口内容纳更多时间步

这两个好处来自**同一个设计决策**，而非两个独立的技巧。这种"一石二鸟"的架构设计展现了很强的工程直觉。

### 7.4 LIBERO-Memory 基准的贡献

SD-VLA 不仅提出了新方法，还指出了现有评估体系的盲点：当前 VLA 基准（LIBERO、SimplerEnv）的任务基本不需要时序记忆，因此无法区分"真正学到了时序建模"还是"恰好在无记忆设置下表现好"。LIBERO-Memory 通过 what/where/when 三维度的情景记忆测试，为评估 VLA 的时序推理能力提供了更有效的工具。

---

## 参考

- [CogACT](https://arxiv.org/abs/2411.19650) — 扩散解码 VLA 基础模型
- [OpenVLA-OFT](https://arxiv.org/abs/2502.19645) — OpenVLA 微调优化
- [VLA-Cache](/papers/06-embodied-ai/vla/efficient/VLA_Cache_2025) — 基于规则的 VLA token 缓存
- [LAC](/papers/06-embodied-ai/vla/efficient/LAC_2026) — 可学习自适应 Token 缓存
- [π₀](/papers/06-embodied-ai/vla/foundation/pi0_2024) — Flow Matching VLA 基础模型
- [InfoNCE](https://arxiv.org/abs/1807.03748) — 对比学习损失函数
- [Gumbel-Softmax](https://arxiv.org/abs/1611.01144) — 离散变量的可微分松弛
